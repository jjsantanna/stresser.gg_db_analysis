{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0. Needed Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "import cfscrape\n",
    "from lxml import etree\n",
    "\n",
    "import os.path\n",
    "\n",
    "import random\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Discovering the middle date of the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'middle_date' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5a3cea99923c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"There is no date in the entire dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdate_tor_check\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmiddle_date\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y-%m-%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mdate_iptoasn_lookup\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmiddle_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'middle_date' is not defined"
     ]
    }
   ],
   "source": [
    "# try:\n",
    "#     try:\n",
    "#         middle_date=(min(df_attacks['date'])+((max(df_attacks['date'])-min(df_attacks['date']))/2))\n",
    "#         raise\n",
    "#     except Exception:\n",
    "#         pass\n",
    "\n",
    "#     try:\n",
    "#         middle_date=(min(df_logins['date'])+((max(df_logins['date'])-min(df_logins['date']))/2))\n",
    "#         raise\n",
    "#     except Exception:\n",
    "#         pass\n",
    "\n",
    "#     try:\n",
    "#         middle_date=(min(df_payments['date'])+((max(df_payments['date'])-min(df_payments['date']))/2))\n",
    "#         raise\n",
    "#     except:\n",
    "#         pass\n",
    "# except Exception:\n",
    "#     print(\"There is no date in the entire dataset\")\n",
    "\n",
    "# date_tor_check = middle_date.strftime('%Y-%m-%d')\n",
    "# date_iptoasn_lookup= str(middle_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Preparing to Perform IP to ASN info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_logins['middledate']=date_iptoasn_lookup\n",
    "# df_attacks['middledate']=date_iptoasn_lookup\n",
    "# df_friendsenemies['middledate']=date_iptoasn_lookup\n",
    "# df_blacklist['middledate']=date_iptoasn_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4.1  Lookup IP to ASN info of table: logins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if (os.path.exists('enrichments/logins_iptoasn_out')== False):\n",
    "#     logins_iptoasn_in = open('enrichments/logins_iptoasn_in', 'w+')\n",
    "#     logins_iptoasn_in.write('begin\\nverbose\\n')\n",
    "#     df_logins[['userip','middledate']].drop_duplicates().to_csv(logins_iptoasn_in,header=False,index=False,sep=\"\\t\") \n",
    "#     logins_iptoasn_in.write('end')\n",
    "#     logins_iptoasn_in.close()\n",
    "\n",
    "#     logins_iptoasn_out = open('enrichments/logins_iptoasn_out', 'w+')\n",
    "#     logins_iptoasn_out.write(iptoasn('enrichments/logins_iptoasn_in'))\n",
    "#     logins_iptoasn_out.close()\n",
    "# else:\n",
    "#     pass\n",
    "# print(\"- Table logins enriched (IP to AS): df_logins_iptoasn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_logins_iptoasn = pd.read_csv('enrichments/logins_iptoasn_out',\\\n",
    "#                                 skiprows=1,\\\n",
    "#                              delimiter=\"\\s+\\|\\s\",\\\n",
    "#                                 engine='python',\\\n",
    "#                              names = ['asn', 'ip', 'bgp_prefix', 'country','registry','info_date','info_request','as_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_logins_extended= pd.merge(df_logins,\n",
    "#                               df_logins_iptoasn,\n",
    "#                               how = 'left',\n",
    "#                               left_on = 'userip',\n",
    "#                               right_on = 'ip')\n",
    "\n",
    "# # Changing name of columns to avoid misunderstandings\n",
    "# df_logins_extended.rename(columns={'asn':'srcasn', \n",
    "#                                    'ip':'srcip', \n",
    "#                                    'bgp_prefix':'srcbgp_prefix', \n",
    "#                                    'country':'srccountry' ,\n",
    "#                                    'registry':'srcregistry',\n",
    "#                                    'info_date':'srcinfo_date',\n",
    "#                                    'info_request':'srcinfo_request'},\n",
    "#                          inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# del df_logins_iptoasn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4.2  Lookup IP to ASN info of table: attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if (os.path.exists('enrichments/attacks_iptoasn_out')== False):\n",
    "#     attacks_iptoasn_in = open('enrichments/attacks_iptoasn_in', 'w+')\n",
    "#     attacks_iptoasn_in.write('begin\\nverbose\\n')\n",
    "#     df_attacks[['targetip','middledate']].drop_duplicates().to_csv(attacks_iptoasn_in,header=False,index=False,sep=\"\\t\") \n",
    "#     attacks_iptoasn_in.write('end')\n",
    "#     attacks_iptoasn_in.close()\n",
    "\n",
    "#     attacks_iptoasn_out = open('enrichments/attacks_iptoasn_out', 'w+')\n",
    "#     attacks_iptoasn_out.write(iptoasn('enrichments/attacks_iptoasn_in'))\n",
    "#     attacks_iptoasn_out.close()\n",
    "# else:\n",
    "#     pass\n",
    "\n",
    "# print(\"- Table attacks enriched (IP to AS): df_attacks_iptoasn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_attacks_iptoasn = pd.read_csv('enrichments/attacks_iptoasn_out',\\\n",
    "#                                 skiprows=1,\\\n",
    "#                              delimiter=r\"\\s+\\|\\s\",\\\n",
    "#                                  engine='python',\\\n",
    "#                              names = ['asn', 'ip', 'bgp_prefix', 'country','registry','info_date','info_request','as_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Merging the iptoasn with the queried column\n",
    "# df_attacks_extended= pd.merge(df_attacks,\n",
    "#                               df_attacks_iptoasn,\n",
    "#                               how = 'left',\n",
    "#                               left_on = 'targetip',\n",
    "#                               right_on = 'ip')\n",
    "\n",
    "# # Changing name of columns to avoid misunderstandings\n",
    "# df_attacks_extended.rename(columns={'asn':'targetasn', \n",
    "#                                    'ip_y':'targetip', \n",
    "#                                    'bgp_prefix':'targetbgp_prefix', \n",
    "#                                    'country_y':'targetcountry' ,\n",
    "#                                    'registry':'targetregistry',\n",
    "#                                    'info_date':'targetinfo_date',\n",
    "#                                    'info_request':'targetinfo_request'},\n",
    "#                          inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# del df_attacks_iptoasn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4.3  Lookup IP to ASN info of table: friendsenemies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if (os.path.exists('enrichments/friendsenemies_iptoasn_out')== False):\n",
    "#     friendsenemies_iptoasn_in = open('enrichments/friendsenemies_iptoasn_in', 'w+')\n",
    "#     friendsenemies_iptoasn_in.write('begin\\nverbose\\n')\n",
    "#     df_friendsenemies[['ip','middledate']].drop_duplicates().to_csv(friendsenemies_iptoasn_in,header=False,index=False,sep=\"\\t\") \n",
    "#     friendsenemies_iptoasn_in.write('end')\n",
    "#     friendsenemies_iptoasn_in.close()\n",
    "\n",
    "#     friendsenemies_iptoasn_out = open('enrichments/friendsenemies_iptoasn_out', 'w+')\n",
    "#     friendsenemies_iptoasn_out.write(iptoasn('enrichments/friendsenemies_iptoasn_in'))\n",
    "#     friendsenemies_iptoasn_out.close()\n",
    "# else:\n",
    "#     pass\n",
    "\n",
    "# print(\"- Table friendsenemies enriched (IP to AS): df_friendsenemies_iptoasn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_friendsenemies_iptoasn = pd.read_csv('enrichments/logins_iptoasn_out',\\\n",
    "#                                 skiprows=1,\\\n",
    "#                              delimiter=\"\\s+\\|\\s\",\\\n",
    "#                             engine='python',\\\n",
    "#                              names = ['asn', 'ip', 'bgp_prefix', 'country','registry','info_date','info_request','as_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_friendsenemies_extended= pd.merge(df_friendsenemies,\n",
    "#                               df_friendsenemies_iptoasn,\n",
    "#                               how = 'left',\n",
    "#                               left_on = 'ip',\n",
    "#                               right_on = 'ip')\n",
    "\n",
    "# # Changing name of columns to avoid misunderstandings\n",
    "# df_friendsenemies_extended.rename(columns={'asn':'friendsenemiesasn', \n",
    "#                                    'ip':'friendsenemiesip', \n",
    "#                                    'bgp_prefix':'friendsenemiesbgp_prefix', \n",
    "#                                    'country':'friendsenemiescountry' ,\n",
    "#                                    'registry':'friendsenemiesregistry',\n",
    "#                                    'info_date':'friendsenemiesinfo_date',\n",
    "#                                    'info_request':'friendsenemiesinfo_request',\n",
    "#                                    'as_name': 'friendsenemiesas_name'},\n",
    "#                          inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# del df_friendsenemies_iptoasn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4.4  Lookup IP to ASN info of table: blacklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if (os.path.exists('enrichments/blacklist_iptoasn_out')== False):\n",
    "#     blacklist_iptoasn_in = open('enrichments/blacklist_iptoasn_in', 'w+')\n",
    "#     blacklist_iptoasn_in.write('begin\\nverbose\\n')\n",
    "#     df_blacklist[['ip','middledate']].drop_duplicates().to_csv(blacklist_iptoasn_in,header=False,index=False,sep=\"\\t\") \n",
    "#     blacklist_iptoasn_in.write('end')\n",
    "#     blacklist_iptoasn_in.close()\n",
    "\n",
    "#     blacklist_iptoasn_out = open('enrichments/blacklist_iptoasn_out', 'w+')\n",
    "#     blacklist_iptoasn_out.write(iptoasn('enrichments/blacklist_iptoasn_in'))\n",
    "#     blacklist_iptoasn_out.close()\n",
    "# else:\n",
    "#     pass\n",
    "\n",
    "# print(\"- Table blacklist enriched (IP to AS): df_blacklist_iptoasn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_blacklist_iptoasn = pd.read_csv('enrichments/blacklist_iptoasn_out',\\\n",
    "#                                 skiprows=1,\\\n",
    "#                              delimiter=\"\\s+\\|\\s\",\\\n",
    "#                                    engine='python',\\\n",
    "#                              names = ['asn', 'ip', 'bgp_prefix', 'country','registry','info_date','info_request','as_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Merging the iptoasn with the queried column\n",
    "# df_blacklist_extended= pd.merge(df_blacklist,\n",
    "#                               df_blacklist_iptoasn,\n",
    "#                               how = 'left',\n",
    "#                               left_on = 'ip',\n",
    "#                               right_on = 'ip')\n",
    "\n",
    "# # Changing name of columns to avoid misunderstandings\n",
    "# df_blacklist_extended.rename(columns={'asn':'blacklistasn', \n",
    "#                                    'ip':'blacklistip', \n",
    "#                                    'bgp_prefix':'blacklistbgp_prefix', \n",
    "#                                    'country':'blacklistcountry' ,\n",
    "#                                    'registry':'blacklistregistry',\n",
    "#                                    'info_date':'blacklistinfo_date',\n",
    "#                                    'info_request':'blacklistinfo_request',\n",
    "#                                    'as_name': 'blacklistas_name'},\n",
    "#                          inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# del df_blacklist_iptoasn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5.1. Check if IP was a TOR node for table: login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (os.path.exists('enrichments/logins_torcheck')== False):\n",
    "    print(\"Note: it can take a while to finish...\")\n",
    "    logins_torcheck = open('enrichments/logins_torcheck', 'w+')\n",
    "    for i in df_logins['userip'].unique():\n",
    "        wasTor=WasTorNode(i,date_tor_check)\n",
    "        print(i, wasTor, file=logins_torcheck)\n",
    "#         print(i, wasTor) #DEBUGING =D\n",
    "        time.sleep(random.randint(1,3)) #adding some random sleep time\n",
    "        logins_torcheck.flush()\n",
    "\n",
    "    logins_torcheck.close()\n",
    "else:\n",
    "    pass\n",
    "\n",
    "print(\"- Table logins enriched (Tor checked): df_logins_torcheck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_logins_torcheck = pd.read_csv('enrichments/logins_torcheck',\\\n",
    "                          delimiter=\"\\s+\",\\\n",
    "                          names = ['userip', 'tor'],\\\n",
    "                                        error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5.2. Check if IP was a TOR node for table: attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (os.path.exists('enrichments/attacks_torcheck')== False):\n",
    "    print(\"Note: it can take a while to finish...\")\n",
    "\n",
    "    attacks_torcheck = open('enrichments/attacks_torcheck', 'w+')\n",
    "    for i in df_attacks['targetip'].unique():\n",
    "        wasTor=WasTorNode(i,date_tor_check)\n",
    "        print(i, wasTor, file=attacks_torcheck)\n",
    "#         print(i, wasTor) #DEBUGING =D\n",
    "        time.sleep(random.randint(1,3)) #adding some random sleep time\n",
    "        attacks_torcheck.flush()\n",
    "    \n",
    "    attacks_torcheck.close()\n",
    "else:\n",
    "    pass\n",
    "\n",
    "print(\"- Table attacks enriched (Tor checked): df_attacks_torcheck\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_attacks_torcheck = pd.read_csv('enrichments/attacks_torcheck',\\\n",
    "                          delimiter=\"\\s+\",\\\n",
    "                          names = ['targetip', 'tor'],\\\n",
    "                                        error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5.3. Check if IP was a TOR node for table: friendsenemies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (os.path.exists('enrichments/friendsenemies_torcheck')== False):\n",
    "    print(\"Note: it can take a while to finish...\")\n",
    "\n",
    "    friendsenemies_torcheck = open('enrichments/friendsenemies_torcheck', 'w+')\n",
    "\n",
    "    for i in df_friendsenemies['ip'].unique():\n",
    "        wasTor=WasTorNode(i,date_tor_check)\n",
    "        print(i, wasTor, file=friendsenemies_torcheck)\n",
    "    #     print(i, wasTor) #DEBUGING =D\n",
    "        time.sleep(random.randint(1,3)) #adding some random sleep time\n",
    "        friendsenemies_torcheck.flush()\n",
    "\n",
    "    friendsenemies_torcheck.close()\n",
    "else:\n",
    "    pass\n",
    "\n",
    "print(\"- Table friendsenemies enriched (Tor checked): df_friendsenemies_torcheck\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_friendsenemies_torcheck = pd.read_csv('enrichments/friendsenemies_torcheck',\\\n",
    "                          delimiter=\"\\s+\",\\\n",
    "                          names = ['ip', 'tor'],\\\n",
    "                                        error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5.4. Check if IP was a TOR node for table: blacklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (os.path.exists('enrichments/blacklist_torcheck')== False):\n",
    "    print(\"Note: it can take a while to finish...\")\n",
    "    \n",
    "    blacklist_torcheck = open('enrichments/blacklist_torcheck', 'w+')\n",
    "\n",
    "    for i in df_blacklist['ip'].unique():\n",
    "        wasTor=WasTorNode(i,date_tor_check)\n",
    "        print(i, wasTor, file=blacklist_torcheck)\n",
    "#         print(i, wasTor) #DEBUGING =D\n",
    "        time.sleep(random.randint(1,3)) #adding some random sleep time\n",
    "        blacklist_torcheck.flush()\n",
    "\n",
    "    blacklist_torcheck.close()\n",
    "else:\n",
    "    pass\n",
    "\n",
    "print(\"- Table blacklist enriched (Tor checked): df_blacklist_torcheck\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_blacklist_torcheck = pd.read_csv('enrichments/blacklist_torcheck',\\\n",
    "                          delimiter=\"\\s+\",\\\n",
    "                          names = ['ip', 'tor'],\\\n",
    "                                        error_bad_lines=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
